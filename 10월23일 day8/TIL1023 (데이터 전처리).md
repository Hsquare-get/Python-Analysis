# TIL1023 (데이터 전처리)

## (1) 누락데이터 처리

> 분석의 정확도는 분석 데이터의 품질에 의해 좌우된다. 데이터 품질을 높이기 위해서는 누락데이터, 중복데이터 등 오류를 수정(누락, 중복데이터 제거 or 대체)하고 분석 목적에 맞게 변형하는 전처리 과정이 필요하다.
>
> <span style="color:red;">**누락데이터(NaN)**</span> : **유효한 데이터 값이 존재하지 않음**



#### (I) 누락 데이터 확인

```python
import seaborn as sns

# titanic 데이터셋 가져오기
df = sns.load_dataset('titanic')

# deck 열의 고유값 개수 카운트(NaN 포함)
nan_deck = df['deck'].value_counts(dropna=False)
print(nan_deck)

# isnull() 메서드로 누락 데이터 찾기
print(df.isnull()) # True of False

# notnull() 메서드로 누락 데이터 찾기
print(df.notnull()) # True of False

# isnull() 메서드로 column별로 누락 데이터 개수 구하기
print(df.isnull().sum(axis=0))
```



#### (II) 누락데이터가 NaN으로 입력되지 않은 경우(0, -, ?)

```python
df.replace('?', np.nan, inplace=True)
```



#### (III) 누락데이터 제거

```python
import seaborn as sns

# titanic 데이터셋 가져오기
df = sns.load_dataset('titanic')

# for 반복문으로 각 열의 NaN 개수 계산하기
missing_df = df.isnull()
for col in missing_df.columns:
    missing_count = missing_df[col].value_counts()    # 각 열의 NaN 개수 파악

    try: 
        print(col, ':', missing_count[True])   # NaN 값이 있으면 개수를 출력
    except:
        print(col, ':', 0)                     # NaN 값이 없으면 0개 출력
        
# NaN 값이 500개 이상인 열을 모두 삭제 - deck 열(891개 중 688개의 NaN 값)
df_thresh = df.dropna(axis=1, thresh=500)  
print(df_thresh.columns)

# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)
df_age = df.dropna(subset=['age'], how='any', axis=0)  
print(len(df_age)) # 714
```



#### (IV) 누락데이터 치환(평균값, 최빈값, 이웃하는값)

```python
import seaborn as sns

# titanic 데이터셋 가져오기
df = sns.load_dataset('titanic')

# age 열의 NaN값을 다른 나이 데이터의 평균으로 변경하기
mean_age = df['age'].mean(axis=0) # age 열의 평균 계산 (NaN 값 제외)
df['age'].fillna(mean_age, inplace=True)

# embark_town 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기
most_freq = df['embark_town'].value_counts(dropna=True).idxmax()   
print(most_freq) # Southampton
df['embark_town'].fillna(most_freq, inplace=True)

# embark_town 열의 NaN값을 바로 앞에 있는 828행의 값으로 변경하기
print(df['embark_town'][825:830])
df['embark_town'].fillna(method='ffill', inplace=True) # method='bfill' (다음행 값으로 치환)
```



## (2) 중복데이터 처리

#### (I) 중복데이터 확인

```python
import pandas as pd

# 중복 데이터를 갖는 데이터프레임 만들기
df = pd.DataFrame({'c1':['a', 'a', 'b', 'a', 'b'],
                  'c2':[1, 1, 1, 2, 2],
                  'c3':[1, 1, 2, 2, 2]})
display(df)

# 데이터프레임 전체 행 데이터 중에서 중복 행 찾기
df_dup = df.duplicated()
print(df_dup) # True or False

# 데이터프레임의 특정 열 데이터에서 중복 행 찾기
col_dup = df['c2'].duplicated()
print(col_dup) # True of False
```



#### (II) 중복데이터 제거

```python
import pandas as pd

# 중복 데이터를 갖는 데이터프레임 만들기
df = pd.DataFrame({'c1':['a', 'a', 'b', 'a', 'b'],
                  'c2':[1, 1, 1, 2, 2],
                  'c3':[1, 1, 2, 2, 2]})

# 데이터프레임에서 중복 행을 제거
df2 = df.drop_duplicates()
print(df2)

# c2, c3열을 기준으로 중복 행을 제거
df3 = df.drop_duplicates(subset=['c2', 'c3'])
print(df3)
```



## (3) 데이터 표준화

> 여러 곳에서 수집한 자료들은 동일한 대상을 표현하는 데 단위, 대소문자 구분, 약칭 활용 등 다양한 형태로 표현되기도 한다. 따라서 데이터 포맷을 일관성 있게 표준화하는 작업이 필요하다. 



#### (I) 단위 환산

```python
import pandas as pd

# read_csv() 함수로 df 생성
df = pd.read_csv('../data/auto-mpg.csv', header=None)

# 열 이름을 지정
df.columns = ['mpg','cylinders','displacement','horsepower','weight',
              'acceleration','model year','origin','name'] 

# mpg(mile per gallon)를 kpl(kilometer per liter)로 변환
mpg_to_kpl = 1.60934 / 3.78541 # 1mpg = 0.425km/L

# mpg 열에 0.425를 곱한 결과를 새로운 열(kpl)에 추가
df['kpl'] = df['mpg'] * mpg_to_kpl 
df['kpl'] = df['kpl'].round(2) # 소수점 아래 둘째 자리에서 반올림
```



#### (II) 자료형 변환

```python
import pandas as pd
import numpy as np

# read_csv() 함수로 df 생성
df = pd.read_csv('../data/auto-mpg.csv', header=None)

# 열 이름을 지정
df.columns = ['mpg','cylinders','displacement','horsepower','weight',
              'acceleration','model year','origin','name'] 

# 각 열의 자료형 확인
print(df.dtypes)

# horsepower 열의 고유값 확인
print(df['horsepower'].unique())

# 누락 데이터('?') 삭제 
df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경
df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제
df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환

# horsepower 열의 자료형 확인
print(df['horsepower'].dtypes) # float64

# origin 열의 고유값 확인
print(df['origin'].unique()) # [1 3 2]

# 정수형 데이터를 문자형 데이터로 변환 
df['origin'].replace({1:'USA', 2:'EU', 3:'JAPAN'}, inplace=True)

# origin 열의 고유값과 자료형 확인
print(df['origin'].unique()) # ['USA' 'JAPAN' 'EU']
print(df['origin'].dtypes) # object

# origin 열의 문자열 자료형을 범주형으로 변환
df['origin'] = df['origin'].astype('category') # category

# 범주형을 문자열로 다시 변환
df['origin'] = df['origin'].astype('str') # object

# model year 열의 정수형을 범주형으로 변환
df['model year'] = df['model year'].astype('category')
```



## (4) 범주형(category) 데이터 처리

> 데이터 분석 알고리즘에 따라서는 연속 데이터를 그대로 사용하기 보다는 일정한 구간(bin)으로 나눠서 분석하는 것이 효율적인 경우가 있다. 연속 변수를 일정한 구간으로 나누고, 각 구간을 범주형 이산 변수로 변환하는 과정을 **구간분할(binning)**이라고 한다.

![binning](https://user-images.githubusercontent.com/64063767/97078565-f2531980-1627-11eb-818b-a9ef10ada52e.jpg)



#### (I) 구간분할

```python
import pandas as pd
import numpy as np

# read_csv() 함수로 df 생성
df = pd.read_csv('../data/auto-mpg.csv', header=None)

# 열 이름을 지정
df.columns = ['mpg','cylinders','displacement','horsepower','weight',
              'acceleration','model year','origin','name'] 

# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환
df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경
df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제
df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환

# np.histogram 함수로 3개의 bin으로 나누는 경계 값의 리스트 구하기
count, bin_dividers = np.histogram(df['horsepower'], bins=3) # 2개의 배열을 담은 튜플반환
print(bin_dividers) # 구간 경계값 4개

# 3개의 bin에 이름 지정
bin_names = ['저출력', '보통출력', '고출력']

# pd.cut() 함수로 각 데이터를 3개의 bin에 할당
df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열(시리즈 객체)
                      bins=bin_dividers,      # 경계 값 리스트
                      labels=bin_names,       # bin 이름
                      include_lowest=True)    # 첫 경계값 포함 

# horsepower 열, hp_bin 열의 첫 15행을 출력
print(df[['horsepower', 'hp_bin']].head(15))
```

![binning](https://user-images.githubusercontent.com/64063767/97078909-a9509480-162a-11eb-81a5-a1159547cda0.png)

---



#### (II) 더미 변수

> 범주형 데이터를 회귀분석 등 머신러닝 알고리즘에 바로 사용할 수 없는 경우가 있는데, 컴퓨터가 인식 가능한 입력값으로 변환해야 한다. 이때 숫자 0 or 1로 표현되는 더미변수(dummy variable)를 사용한다.
>
> 범주형 데이터를 컴퓨터가 인식할 수 있도록 숫자 0과 1로만 구성되는 **one hot vector**로 변환한다고 해서 **one-hot-encoding**이라고도 부른다.
>
> 판다스 `get_dummies()` 함수를 사용하면, 범주형 변수의 모든 고유값을 각각 새로운 더미 변수로 변환한다. 고유값이 많으면 그만큼 더미변수가 많아지는 단점도 존재한다. 

```python
"""
import pandas as pd
import numpy as np

# read_csv() 함수로 df 생성
df = pd.read_csv('../data/auto-mpg.csv', header=None)

# 열 이름을 지정
df.columns = ['mpg','cylinders','displacement','horsepower','weight',
              'acceleration','model year','origin','name'] 

# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환
df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경
df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제
df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환

# np.histogram 으로 3개의 bin으로 나누는 경계 값의 리스트 구하기
count, bin_dividers = np.histogram(df['horsepower'], bins=3)

# 3개의 bin에 이름 지정
bin_names = ['저출력', '보통출력', '고출력']

# pd.cut 으로 각 데이터를 3개의 bin에 할당
df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열
                      bins=bin_dividers,      # 경계 값 리스트
                      labels=bin_names,       # bin 이름
                      include_lowest=True)    # 첫 경계값 포함
"""

# hp_bin 열의 범주형 데이터를 더미 변수로 변환
horsepower_dummies = pd.get_dummies(df['hp_bin'])
print(horsepower_dummies.head(15))
```

![dummy variable](https://user-images.githubusercontent.com/64063767/97078920-bec5be80-162a-11eb-9422-2efe73df899b.png)

---

- **skleran 라이브러리 이용해서 one-hot-encoding 처리**

```python
"""
import pandas as pd
import numpy as np

# read_csv() 함수로 df 생성
df = pd.read_csv('../data/auto-mpg.csv', header=None)

# 열 이름을 지정
df.columns = ['mpg','cylinders','displacement','horsepower','weight',
              'acceleration','model year','origin','name'] 

# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환
df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경
df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제
df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환

# np.histogram 으로 3개의 bin으로 나누는 경계 값의 리스트 구하기
count, bin_dividers = np.histogram(df['horsepower'], bins=3)

# 3개의 bin에 이름 지정
bin_names = ['저출력', '보통출력', '고출력']

# pd.cut 으로 각 데이터를 3개의 bin에 할당
df['hp_bin'] = pd.cut(x=df['horsepower'],     # 데이터 배열
                      bins=bin_dividers,      # 경계 값 리스트
                      labels=bin_names,       # bin 이름
                      include_lowest=True)    # 첫 경계값 포함
"""

# sklern 라이브러리 불러오기
from sklearn import preprocessing    

# 전처리를 위한 encoder 객체 만들기
label_encoder = preprocessing.LabelEncoder()     # label encoder 생성
onehot_encoder = preprocessing.OneHotEncoder()   # one hot encoder 생성

# label encoder로 문자열 범주를 숫자형 범주로 변환
onehot_labeled = label_encoder.fit_transform(df['hp_bin']) # df['hp_bin'].head(15)  
print(onehot_labeled)

# 2차원 행렬로 형태 변경
onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled), 1) 
print(onehot_reshaped)

# 희소행렬로 변환 [(행, 열), 값]
onehot_fitted = onehot_encoder.fit_transform(onehot_reshaped)
print(onehot_fitted)
```

![one-hot-encoding](https://user-images.githubusercontent.com/64063767/97079170-b8d0dd00-162c-11eb-804e-7025e4316d1a.png)

---



## (5) 정규화

> 각 변수(데이터프레임 열)에 들어있는 숫자 데이터의 상대적 크기 차이 떄문에 머신러닝 분석 결과가 달라질 수 있다. 각 열(변수)에 속하는 데이터 값을 동일한 크기 기준으로 나눈 비율로 나타내는 것을 **정규화(normalization)**라고 한다. 정규화 과정을 거친 데이터의 범위는 (0,1) or (-1, 1) 사이 값을 갖는다.



#### (I) 각 열의 데이터를 해당 열의 최대값의 절대값으로 나누는 방법

```python
import pandas as pd
import numpy as np

# read_csv() 함수로 df 생성
df = pd.read_csv('../data/auto-mpg.csv', header=None)

# 열 이름을 지정
df.columns = ['mpg','cylinders','displacement','horsepower','weight',
              'acceleration','model year','origin','name']  

# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환
df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경
df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제
df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환

# horsepower 열의 통계 요약정보로 최대값(max)을 확인
print(df.horsepower.describe())

# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장
df.horsepower = df.horsepower / abs(df.horsepower.max()) 
```



#### (II) 각 열의 데이터에서 최소값을 빼고, 최대값과 최소값의 차이로 나누는 방법

$$
(각 열의 데이터 x - 최소값) / (최대값 - 최소값)
$$

```python
import pandas as pd
import numpy as np

# read_csv() 함수로 df 생성
df = pd.read_csv('../data/auto-mpg.csv', header=None)

# 열 이름을 지정
df.columns = ['mpg','cylinders','displacement','horsepower','weight',
              'acceleration','model year','origin','name']  

# horsepower 열의 누락 데이터('?') 삭제하고 실수형으로 변환
df['horsepower'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경
df.dropna(subset=['horsepower'], axis=0, inplace=True)   # 누락데이터 행을 삭제
df['horsepower'] = df['horsepower'].astype('float')      # 문자열을 실수형으로 변환

# horsepower 열의 통계 요약정보로 최대값(max)과 최소값(min)을 확인
print(df.horsepower.describe())

# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장
min_x = df.horsepower - df.horsepower.min()
min_max = df.horsepower.max() - df.horsepower.min()
df.horsepower = min_x / min_max
```



## (6) 시계열 데이터

> 특정한 시점을 기록하는 **Timestamp**, 두 시점 사이의 일정한 기간을 나타내는 **Period**로 시계열 데이터를 표현한다. 

![timestamp,period](https://user-images.githubusercontent.com/64063767/97080978-45ce6300-163a-11eb-97e2-6b162f7c6b86.jpg)



#### (I) 다른 자료형을 시계열 객체로 변환

- **문자열을 Timestamp로 변환**

```python
import pandas as pd

# read_csv() 함수로 CSV 파일을 가져와서 df로 변환
df = pd.read_csv('../data/stock-data.csv')

# 데이터 내용 및 자료형 자료형 확인
print(df.head())
print(df.info())

# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환
df['new_Date'] = pd.to_datetime(df['Date'])

# 데이터 내용 및 자료형 자료형 확인
print(df.head())
print(df.info())

# 시계열 값으로 변환된 열을 새로운 행 인덱스로 지정
df.set_index('new_Date', inplace=True)
df.drop('Date', axis=1, inplace=True) # 기존 날짜 열은 삭제
```



- **Timestamp를 Period로 변환**
  - 202010231036와 같이 숫자형일 경우 strp(str, format)로 문자열로 바꾼 후 to_period()

```python
import pandas as pd

# 날짜 형식의 문자열로 구성되는 리스트 정의
dates = ['2019-01-01', '2020-03-01', '2021-06-01']

# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환
ts_dates = pd.to_datetime(dates)   
print(ts_dates)

# Timestamp를 Period로 변환
pr_day = ts_dates.to_period(freq='D')
print(pr_day)
pr_month = ts_dates.to_period(freq='M')
print(pr_month)
pr_year = ts_dates.to_period(freq='A')
print(pr_year)
```

![timestamptoperiod](https://user-images.githubusercontent.com/64063767/97081505-ce023780-163d-11eb-830c-ac537e5a0e72.png)

| freq 옵션                            | 설명                                 |
| ------------------------------------ | ------------------------------------ |
| freq = "D"                           | day(일)                              |
| freq = "W"                           | week(1주)                            |
| freq = "M"                           | month end(월말)                      |
| freq = "MS"                          | month start(월초)                    |
| freq = "Q"                           | quarter end(분기말)                  |
| freq = "QS"                          | quarter start(분기초)                |
| freq = "A"                           | year end(연말)                       |
| freq = "AS"                          | year start(연초)                     |
| freq = "B"                           | business day(휴일 제외)              |
| freq = "H"                           | hour(1시간)                          |
| freq = "T"                           | minute(1분)                          |
| freq = "S"                           | second(1초)                          |
| freq = "L" / freq = "U" / freq = "N" | millisecond, microsecond, nanosecond |

---



#### (II) 시계열 데이터 만들기

- **Timestamp 배열**

```python
import pandas as pd

# Timestamp의 배열 만들기 - 월 간격, 월의 시작일 기준
ts_ms = pd.date_range(start='2019-01-01',    # 날짜 범위의 시작
                   end=None,                 # 날짜 범위의 끝
                   periods=6,                # 생성할 Timestamp의 개수
                   freq='MS',                # 시간 간격 (MS: 월의 시작일)
                   tz='Asia/Seoul')          # 시간대(timezone)
print(ts_ms)

# 월 간격, 월의 마지막 날 기준
ts_me = pd.date_range('2019-01-01', periods=6, 
                   freq='M',                 # 시간 간격 (M: 월의 마지막 날)
                   tz='Asia/Seoul')          # 시간대(timezone)
print(ts_me)

# 분기(3개월) 간격, 월의 마지막 날 기준
ts_3m = pd.date_range('2019-01-01', periods=6, 
                   freq='3M',                # 시간 간격 (3M: 3개월)
                   tz='Asia/Seoul')          # 시간대(timezone)
print(ts_3m)
```

![timestamparray](https://user-images.githubusercontent.com/64063767/97081795-bfb51b00-163f-11eb-8539-17589ce48d34.png)

---



- **Period 배열**

```python
import pandas as pd

# Period 배열 만들기 - 1개월 길이
pr_m = pd.period_range(start='2019-01-01',     # 날짜 범위의 시작
                   end=None,                   # 날짜 범위의 끝
                   periods=3,                  # 생성할 Period 개수
                   freq='M')                   # 기간의 길이 (M: 월)
print(pr_m)

# Period 배열 만들기 - 1시간 길이
pr_h = pd.period_range(start='2019-01-01',     # 날짜 범위의 시작
                   end=None,                   # 날짜 범위의 끝
                   periods=3,                  # 생성할 Period 개수
                   freq='H')                   # 기간의 길이 (H: 시간)
print(pr_h)

# Period 배열 만들기 - 2시간 길이
pr_2h = pd.period_range(start='2019-01-01',    # 날짜 범위의 시작
                   end=None,                   # 날짜 범위의 끝
                   periods=3,                  # 생성할 Period 개수
                   freq='2H')                  # 기간의 길이 (2H: 2시간)
print(pr_2h)
```

![periodarray](https://user-images.githubusercontent.com/64063767/97081844-25a1a280-1640-11eb-9e2b-8db97a6d7c65.png)

---



#### (III) 시계열 데이터 활용

- **날짜 데이터 분리**

```python
import pandas as pd

# read_csv() 함수로 파일 읽어와서 df로 변환
df = pd.read_csv('../data/stock-data.csv')
display(df.head())

# 문자열인 날짜 데이터를 판다스 Timestamp로 변환
df['new_Date'] = pd.to_datetime(df['Date'])

# dt 속성을 이용하여 new_Date 열의 년월일 정보를 년, 월, 일로 구분
df['Year'] = df['new_Date'].dt.year
df['Month'] = df['new_Date'].dt.month
df['Day'] = df['new_Date'].dt.day

# Timestamp를 Period로 변환하여 년월일 표기 변경하기
df['Date_yr'] = df['new_Date'].dt.to_period(freq='A')
df['Date_m'] = df['new_Date'].dt.to_period(freq='M')

display(df.loc[:,'new_Date':'Date_m'])
```

![divide date](https://user-images.githubusercontent.com/64063767/97082072-de1c1600-1641-11eb-8541-38413fe5fb54.png)

---



- **날짜 인덱스 활용**

```python
import pandas as pd

# read_csv() 함수로 파일 읽어와서 df로 변환
df = pd.read_csv('../data/stock-data.csv')

# 문자열인 날짜 데이터를 판다스 Timestamp로 변환
df['new_Date'] = pd.to_datetime(df['Date'])
df.set_index('new_Date', inplace=True)

# 날짜 인덱스를 이용하여 데이터 선택하기
df_y = df.loc['2018']
display(df_y.head()) # 2018년인 행 전체

df_ym = df.loc['2018-07'] # 2018년 7월인 행 전체
display(df_ym)

df_ymd = df.loc['2018-07-02'] # 2018년 7월 2일인 행 전체
display(df_ymd)

df_ym_cols = df.loc['2018-07', 'Close':'Low'] # 2018년 7월인 행 전체에서 Close~Low 열만
display(df_ym_cols)

df_ymd_range = df['2018-06-23':'2018-06-20'] # 2018-06-23 ~ 2018-06-20인 행 전체
display(df_ymd_range)

# 시간 간격 계산. 2018-12-25기준 최근 180일 ~ 189일 사이의 값들만 선택하기
today = pd.to_datetime('2018-12-25')            # 기준일 생성
df['time_delta'] = today - df.index             # 날짜 차이 계산
df.set_index('time_delta', inplace=True)        # 행 인덱스로 지정
df_180 = df['180 days':'189 days']
display(df_180)
```

